{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575301ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sqrt\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d0de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return asarray(X), asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b42bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-car-sales.csv'\n",
    "df = read_csv(path, header=0, index_col=0, squeeze=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf26453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month\n",
       "1960-01     6550\n",
       "1960-02     8728\n",
       "1960-03    12026\n",
       "1960-04    14395\n",
       "1960-05    14587\n",
       "Name: Sales, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc79b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.values.astype('float32')\n",
    "# specify the window size\n",
    "n_steps = 5\n",
    "# split into samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a2ea73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a97acebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_sequence(values, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19781467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d08b2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6550.,  8728., 12026., 14395., 14587.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5237a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "# split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28b876ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6550.],\n",
       "       [ 8728.],\n",
       "       [12026.],\n",
       "       [14395.],\n",
       "       [14587.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74b72fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 5, 1) (12, 5, 1) (91,) (12,)\n"
     ]
    }
   ],
   "source": [
    "n_test = 12\n",
    "X_train, X_test, y_train, y_test = X[:-n_test], X[-n_test:], y[:-n_test], y[-n_test:]\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5670d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_steps,1)))\n",
    "model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "228c73c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "3/3 - 3s - loss: 516287840.0000 - mae: 21784.6348 - val_loss: 319541984.0000 - val_mae: 17445.9023\n",
      "Epoch 2/350\n",
      "3/3 - 0s - loss: 111133704.0000 - mae: 9029.0068 - val_loss: 34786780.0000 - val_mae: 5054.1934\n",
      "Epoch 3/350\n",
      "3/3 - 0s - loss: 31400358.0000 - mae: 4321.3389 - val_loss: 79924112.0000 - val_mae: 7681.8843\n",
      "Epoch 4/350\n",
      "3/3 - 0s - loss: 64553364.0000 - mae: 6537.9473 - val_loss: 66767228.0000 - val_mae: 6929.6636\n",
      "Epoch 5/350\n",
      "3/3 - 0s - loss: 46073040.0000 - mae: 5378.5420 - val_loss: 29187704.0000 - val_mae: 4804.2192\n",
      "Epoch 6/350\n",
      "3/3 - 0s - loss: 25631530.0000 - mae: 4022.6619 - val_loss: 20922734.0000 - val_mae: 3528.8777\n",
      "Epoch 7/350\n",
      "3/3 - 0s - loss: 21480996.0000 - mae: 3784.1689 - val_loss: 31026390.0000 - val_mae: 4196.4771\n",
      "Epoch 8/350\n",
      "3/3 - 0s - loss: 25948114.0000 - mae: 4094.6721 - val_loss: 33196666.0000 - val_mae: 4365.7397\n",
      "Epoch 9/350\n",
      "3/3 - 0s - loss: 24665678.0000 - mae: 4004.2583 - val_loss: 26318112.0000 - val_mae: 3765.7258\n",
      "Epoch 10/350\n",
      "3/3 - 0s - loss: 20104336.0000 - mae: 3632.3042 - val_loss: 19308712.0000 - val_mae: 3528.4863\n",
      "Epoch 11/350\n",
      "3/3 - 0s - loss: 18308704.0000 - mae: 3440.6614 - val_loss: 20566006.0000 - val_mae: 3868.9949\n",
      "Epoch 12/350\n",
      "3/3 - 0s - loss: 18664264.0000 - mae: 3433.0947 - val_loss: 20793862.0000 - val_mae: 3955.4609\n",
      "Epoch 13/350\n",
      "3/3 - 0s - loss: 18580424.0000 - mae: 3423.1978 - val_loss: 18562274.0000 - val_mae: 3700.2371\n",
      "Epoch 14/350\n",
      "3/3 - 0s - loss: 16938870.0000 - mae: 3277.8325 - val_loss: 17515952.0000 - val_mae: 3500.7012\n",
      "Epoch 15/350\n",
      "3/3 - 0s - loss: 15967820.0000 - mae: 3212.5535 - val_loss: 17962416.0000 - val_mae: 3366.1875\n",
      "Epoch 16/350\n",
      "3/3 - 0s - loss: 16026627.0000 - mae: 3263.6472 - val_loss: 18028738.0000 - val_mae: 3324.9597\n",
      "Epoch 17/350\n",
      "3/3 - 0s - loss: 15863617.0000 - mae: 3237.1404 - val_loss: 17107002.0000 - val_mae: 3319.0989\n",
      "Epoch 18/350\n",
      "3/3 - 0s - loss: 15201184.0000 - mae: 3133.3447 - val_loss: 16250437.0000 - val_mae: 3374.4290\n",
      "Epoch 19/350\n",
      "3/3 - 0s - loss: 15063212.0000 - mae: 3117.6033 - val_loss: 16127669.0000 - val_mae: 3480.7512\n",
      "Epoch 20/350\n",
      "3/3 - 0s - loss: 14661559.0000 - mae: 3069.2170 - val_loss: 15768092.0000 - val_mae: 3435.5642\n",
      "Epoch 21/350\n",
      "3/3 - 0s - loss: 14095792.0000 - mae: 3016.3228 - val_loss: 16044539.0000 - val_mae: 3454.0400\n",
      "Epoch 22/350\n",
      "3/3 - 0s - loss: 13272108.0000 - mae: 2906.4854 - val_loss: 16026331.0000 - val_mae: 3371.1064\n",
      "Epoch 23/350\n",
      "3/3 - 0s - loss: 13042210.0000 - mae: 2855.6970 - val_loss: 15543199.0000 - val_mae: 3284.3145\n",
      "Epoch 24/350\n",
      "3/3 - 0s - loss: 12424651.0000 - mae: 2741.6299 - val_loss: 15194433.0000 - val_mae: 3401.6094\n",
      "Epoch 25/350\n",
      "3/3 - 0s - loss: 11364563.0000 - mae: 2626.4441 - val_loss: 18146254.0000 - val_mae: 3782.1555\n",
      "Epoch 26/350\n",
      "3/3 - 0s - loss: 11502271.0000 - mae: 2650.2954 - val_loss: 15894893.0000 - val_mae: 3570.0322\n",
      "Epoch 27/350\n",
      "3/3 - 0s - loss: 11731872.0000 - mae: 2691.3870 - val_loss: 15222853.0000 - val_mae: 3469.9500\n",
      "Epoch 28/350\n",
      "3/3 - 0s - loss: 11116876.0000 - mae: 2582.5078 - val_loss: 13715219.0000 - val_mae: 3041.7117\n",
      "Epoch 29/350\n",
      "3/3 - 0s - loss: 10800914.0000 - mae: 2523.6912 - val_loss: 12978208.0000 - val_mae: 2949.9883\n",
      "Epoch 30/350\n",
      "3/3 - 0s - loss: 10746128.0000 - mae: 2503.4783 - val_loss: 13201339.0000 - val_mae: 2967.2678\n",
      "Epoch 31/350\n",
      "3/3 - 0s - loss: 10664514.0000 - mae: 2481.7439 - val_loss: 13019381.0000 - val_mae: 3022.1191\n",
      "Epoch 32/350\n",
      "3/3 - 0s - loss: 10713151.0000 - mae: 2529.7756 - val_loss: 12842829.0000 - val_mae: 3277.0293\n",
      "Epoch 33/350\n",
      "3/3 - 0s - loss: 10323702.0000 - mae: 2485.1038 - val_loss: 12430240.0000 - val_mae: 3009.2461\n",
      "Epoch 34/350\n",
      "3/3 - 0s - loss: 9988673.0000 - mae: 2403.4233 - val_loss: 13140128.0000 - val_mae: 2892.4163\n",
      "Epoch 35/350\n",
      "3/3 - 0s - loss: 9762948.0000 - mae: 2398.3083 - val_loss: 11778868.0000 - val_mae: 2881.0261\n",
      "Epoch 36/350\n",
      "3/3 - 0s - loss: 9476666.0000 - mae: 2364.8765 - val_loss: 11489744.0000 - val_mae: 2948.3848\n",
      "Epoch 37/350\n",
      "3/3 - 0s - loss: 9339290.0000 - mae: 2356.6150 - val_loss: 11701043.0000 - val_mae: 2781.5188\n",
      "Epoch 38/350\n",
      "3/3 - 0s - loss: 9207097.0000 - mae: 2341.4822 - val_loss: 12050641.0000 - val_mae: 2766.4080\n",
      "Epoch 39/350\n",
      "3/3 - 0s - loss: 9165031.0000 - mae: 2330.8743 - val_loss: 11617932.0000 - val_mae: 2759.3845\n",
      "Epoch 40/350\n",
      "3/3 - 0s - loss: 8991021.0000 - mae: 2315.5391 - val_loss: 11560672.0000 - val_mae: 2745.5110\n",
      "Epoch 41/350\n",
      "3/3 - 0s - loss: 8863601.0000 - mae: 2300.8286 - val_loss: 11454900.0000 - val_mae: 2788.5613\n",
      "Epoch 42/350\n",
      "3/3 - 0s - loss: 8725822.0000 - mae: 2291.8823 - val_loss: 11335536.0000 - val_mae: 2779.2898\n",
      "Epoch 43/350\n",
      "3/3 - 0s - loss: 8883502.0000 - mae: 2295.9939 - val_loss: 11612331.0000 - val_mae: 2849.0750\n",
      "Epoch 44/350\n",
      "3/3 - 0s - loss: 8861008.0000 - mae: 2286.3245 - val_loss: 11210679.0000 - val_mae: 2820.4441\n",
      "Epoch 45/350\n",
      "3/3 - 0s - loss: 8786393.0000 - mae: 2281.4932 - val_loss: 11175504.0000 - val_mae: 2831.9766\n",
      "Epoch 46/350\n",
      "3/3 - 0s - loss: 8712266.0000 - mae: 2256.7561 - val_loss: 11174779.0000 - val_mae: 2766.2532\n",
      "Epoch 47/350\n",
      "3/3 - 0s - loss: 8493432.0000 - mae: 2236.6531 - val_loss: 11190331.0000 - val_mae: 2741.5410\n",
      "Epoch 48/350\n",
      "3/3 - 0s - loss: 8572887.0000 - mae: 2241.8894 - val_loss: 11314351.0000 - val_mae: 2712.6895\n",
      "Epoch 49/350\n",
      "3/3 - 0s - loss: 8394387.0000 - mae: 2204.7053 - val_loss: 10998985.0000 - val_mae: 2690.0369\n",
      "Epoch 50/350\n",
      "3/3 - 0s - loss: 8396638.0000 - mae: 2258.0767 - val_loss: 10569967.0000 - val_mae: 2747.0342\n",
      "Epoch 51/350\n",
      "3/3 - 0s - loss: 8476735.0000 - mae: 2237.6421 - val_loss: 10820959.0000 - val_mae: 2573.1614\n",
      "Epoch 52/350\n",
      "3/3 - 0s - loss: 8233439.5000 - mae: 2197.2097 - val_loss: 10885689.0000 - val_mae: 2563.7957\n",
      "Epoch 53/350\n",
      "3/3 - 0s - loss: 8230790.5000 - mae: 2189.4534 - val_loss: 10683002.0000 - val_mae: 2555.4124\n",
      "Epoch 54/350\n",
      "3/3 - 0s - loss: 8105401.5000 - mae: 2191.6240 - val_loss: 10700057.0000 - val_mae: 2563.6819\n",
      "Epoch 55/350\n",
      "3/3 - 0s - loss: 8070535.0000 - mae: 2184.8972 - val_loss: 10794859.0000 - val_mae: 2535.7603\n",
      "Epoch 56/350\n",
      "3/3 - 0s - loss: 8124773.5000 - mae: 2193.8503 - val_loss: 10810768.0000 - val_mae: 2556.1631\n",
      "Epoch 57/350\n",
      "3/3 - 0s - loss: 7959895.0000 - mae: 2163.4583 - val_loss: 10993090.0000 - val_mae: 2559.5635\n",
      "Epoch 58/350\n",
      "3/3 - 0s - loss: 8026985.0000 - mae: 2161.2705 - val_loss: 10943900.0000 - val_mae: 2552.9717\n",
      "Epoch 59/350\n",
      "3/3 - 0s - loss: 7925442.0000 - mae: 2147.6956 - val_loss: 10889901.0000 - val_mae: 2532.7295\n",
      "Epoch 60/350\n",
      "3/3 - 0s - loss: 7983312.0000 - mae: 2180.1763 - val_loss: 10878021.0000 - val_mae: 2600.5986\n",
      "Epoch 61/350\n",
      "3/3 - 0s - loss: 7781801.0000 - mae: 2169.4639 - val_loss: 11025244.0000 - val_mae: 2537.9241\n",
      "Epoch 62/350\n",
      "3/3 - 0s - loss: 7778425.0000 - mae: 2137.1626 - val_loss: 11322028.0000 - val_mae: 2555.4504\n",
      "Epoch 63/350\n",
      "3/3 - 0s - loss: 7852376.0000 - mae: 2147.3359 - val_loss: 11089175.0000 - val_mae: 2532.3313\n",
      "Epoch 64/350\n",
      "3/3 - 0s - loss: 7695308.0000 - mae: 2151.4109 - val_loss: 10912031.0000 - val_mae: 2623.2073\n",
      "Epoch 65/350\n",
      "3/3 - 0s - loss: 7739776.5000 - mae: 2182.0872 - val_loss: 11016000.0000 - val_mae: 2522.5969\n",
      "Epoch 66/350\n",
      "3/3 - 0s - loss: 7920870.5000 - mae: 2142.4001 - val_loss: 11494872.0000 - val_mae: 2665.0012\n",
      "Epoch 67/350\n",
      "3/3 - 0s - loss: 7786031.0000 - mae: 2180.6821 - val_loss: 10747407.0000 - val_mae: 2528.4368\n",
      "Epoch 68/350\n",
      "3/3 - 0s - loss: 7916615.5000 - mae: 2217.4182 - val_loss: 10701027.0000 - val_mae: 2465.2312\n",
      "Epoch 69/350\n",
      "3/3 - 0s - loss: 7900580.0000 - mae: 2140.1375 - val_loss: 12115463.0000 - val_mae: 2764.5735\n",
      "Epoch 70/350\n",
      "3/3 - 0s - loss: 7549546.0000 - mae: 2108.1379 - val_loss: 10838490.0000 - val_mae: 2528.2659\n",
      "Epoch 71/350\n",
      "3/3 - 0s - loss: 7798196.5000 - mae: 2208.0847 - val_loss: 10980092.0000 - val_mae: 2577.6848\n",
      "Epoch 72/350\n",
      "3/3 - 0s - loss: 7390818.5000 - mae: 2165.0247 - val_loss: 11470241.0000 - val_mae: 2626.5461\n",
      "Epoch 73/350\n",
      "3/3 - 0s - loss: 7567723.0000 - mae: 2130.4985 - val_loss: 11731211.0000 - val_mae: 2641.7068\n",
      "Epoch 74/350\n",
      "3/3 - 0s - loss: 7088660.5000 - mae: 2093.1641 - val_loss: 13211584.0000 - val_mae: 2879.7200\n",
      "Epoch 75/350\n",
      "3/3 - 0s - loss: 7161363.5000 - mae: 2137.0779 - val_loss: 13513084.0000 - val_mae: 2978.1023\n",
      "Epoch 76/350\n",
      "3/3 - 0s - loss: 7069565.0000 - mae: 2143.2903 - val_loss: 13071819.0000 - val_mae: 2861.9773\n",
      "Epoch 77/350\n",
      "3/3 - 0s - loss: 7123781.0000 - mae: 2082.7205 - val_loss: 13314379.0000 - val_mae: 2895.6719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/350\n",
      "3/3 - 0s - loss: 7101091.0000 - mae: 2071.7629 - val_loss: 13390984.0000 - val_mae: 2906.5115\n",
      "Epoch 79/350\n",
      "3/3 - 0s - loss: 6941039.0000 - mae: 2109.0513 - val_loss: 13646416.0000 - val_mae: 2933.6926\n",
      "Epoch 80/350\n",
      "3/3 - 0s - loss: 6890925.0000 - mae: 2102.4148 - val_loss: 13694269.0000 - val_mae: 2940.9124\n",
      "Epoch 81/350\n",
      "3/3 - 0s - loss: 6795404.0000 - mae: 2069.8877 - val_loss: 13727545.0000 - val_mae: 2935.9121\n",
      "Epoch 82/350\n",
      "3/3 - 0s - loss: 6897309.5000 - mae: 2067.2751 - val_loss: 13909115.0000 - val_mae: 2951.7324\n",
      "Epoch 83/350\n",
      "3/3 - 0s - loss: 6781619.5000 - mae: 2072.6323 - val_loss: 14297029.0000 - val_mae: 3021.0020\n",
      "Epoch 84/350\n",
      "3/3 - 0s - loss: 6800573.0000 - mae: 2093.6809 - val_loss: 14278379.0000 - val_mae: 2995.2898\n",
      "Epoch 85/350\n",
      "3/3 - 0s - loss: 6889870.0000 - mae: 2067.9307 - val_loss: 14134677.0000 - val_mae: 2965.3157\n",
      "Epoch 86/350\n",
      "3/3 - 0s - loss: 6762528.5000 - mae: 2053.6096 - val_loss: 13965744.0000 - val_mae: 2984.2793\n",
      "Epoch 87/350\n",
      "3/3 - 0s - loss: 6771836.0000 - mae: 2106.3054 - val_loss: 14071211.0000 - val_mae: 2995.0710\n",
      "Epoch 88/350\n",
      "3/3 - 0s - loss: 6705913.0000 - mae: 2081.6289 - val_loss: 14332991.0000 - val_mae: 3003.4109\n",
      "Epoch 89/350\n",
      "3/3 - 0s - loss: 6684215.5000 - mae: 2048.1482 - val_loss: 14541533.0000 - val_mae: 3021.3420\n",
      "Epoch 90/350\n",
      "3/3 - 0s - loss: 6645471.5000 - mae: 2052.3625 - val_loss: 14587763.0000 - val_mae: 3052.1345\n",
      "Epoch 91/350\n",
      "3/3 - 0s - loss: 6619214.0000 - mae: 2051.1318 - val_loss: 14436764.0000 - val_mae: 3032.4600\n",
      "Epoch 92/350\n",
      "3/3 - 0s - loss: 6569954.0000 - mae: 2031.9227 - val_loss: 14367285.0000 - val_mae: 3015.1477\n",
      "Epoch 93/350\n",
      "3/3 - 0s - loss: 6519936.5000 - mae: 2022.7264 - val_loss: 14357739.0000 - val_mae: 3017.6628\n",
      "Epoch 94/350\n",
      "3/3 - 0s - loss: 6580467.5000 - mae: 2041.5963 - val_loss: 14223400.0000 - val_mae: 3020.0537\n",
      "Epoch 95/350\n",
      "3/3 - 0s - loss: 6332885.0000 - mae: 1981.4379 - val_loss: 12087621.0000 - val_mae: 2738.2131\n",
      "Epoch 96/350\n",
      "3/3 - 0s - loss: 7208261.0000 - mae: 2049.8540 - val_loss: 12343664.0000 - val_mae: 2607.0779\n",
      "Epoch 97/350\n",
      "3/3 - 0s - loss: 7253794.0000 - mae: 2085.3921 - val_loss: 11251200.0000 - val_mae: 2645.0732\n",
      "Epoch 98/350\n",
      "3/3 - 0s - loss: 6622127.0000 - mae: 1947.1813 - val_loss: 11842475.0000 - val_mae: 2514.4312\n",
      "Epoch 99/350\n",
      "3/3 - 0s - loss: 7566304.5000 - mae: 2050.6782 - val_loss: 11638164.0000 - val_mae: 2505.9573\n",
      "Epoch 100/350\n",
      "3/3 - 0s - loss: 7366433.0000 - mae: 2064.1057 - val_loss: 10846935.0000 - val_mae: 2624.6199\n",
      "Epoch 101/350\n",
      "3/3 - 0s - loss: 7294493.5000 - mae: 2110.7654 - val_loss: 11148919.0000 - val_mae: 2505.5095\n",
      "Epoch 102/350\n",
      "3/3 - 0s - loss: 7175461.5000 - mae: 1977.4155 - val_loss: 12048972.0000 - val_mae: 2619.1575\n",
      "Epoch 103/350\n",
      "3/3 - 0s - loss: 7100553.0000 - mae: 1992.9550 - val_loss: 10903556.0000 - val_mae: 2592.5808\n",
      "Epoch 104/350\n",
      "3/3 - 0s - loss: 7024689.0000 - mae: 2052.9070 - val_loss: 10954404.0000 - val_mae: 2624.7625\n",
      "Epoch 105/350\n",
      "3/3 - 0s - loss: 6913383.5000 - mae: 2011.3705 - val_loss: 11098245.0000 - val_mae: 2507.4084\n",
      "Epoch 106/350\n",
      "3/3 - 0s - loss: 7370144.5000 - mae: 2022.9304 - val_loss: 11462025.0000 - val_mae: 2564.8745\n",
      "Epoch 107/350\n",
      "3/3 - 0s - loss: 7063697.0000 - mae: 1990.2672 - val_loss: 11256915.0000 - val_mae: 2708.8938\n",
      "Epoch 108/350\n",
      "3/3 - 0s - loss: 7041908.0000 - mae: 2068.3765 - val_loss: 10991723.0000 - val_mae: 2548.9563\n",
      "Epoch 109/350\n",
      "3/3 - 0s - loss: 6910071.5000 - mae: 1930.5670 - val_loss: 11704696.0000 - val_mae: 2553.8464\n",
      "Epoch 110/350\n",
      "3/3 - 0s - loss: 6758698.0000 - mae: 1909.1597 - val_loss: 12170805.0000 - val_mae: 2697.8840\n",
      "Epoch 111/350\n",
      "3/3 - 0s - loss: 6927084.5000 - mae: 2019.7932 - val_loss: 12106259.0000 - val_mae: 2698.5879\n",
      "Epoch 112/350\n",
      "3/3 - 0s - loss: 6606038.0000 - mae: 1916.5337 - val_loss: 11318391.0000 - val_mae: 2665.7874\n",
      "Epoch 113/350\n",
      "3/3 - 0s - loss: 6835337.0000 - mae: 1941.0225 - val_loss: 10833340.0000 - val_mae: 2559.5186\n",
      "Epoch 114/350\n",
      "3/3 - 0s - loss: 7085590.0000 - mae: 2047.2351 - val_loss: 10947891.0000 - val_mae: 2675.4026\n",
      "Epoch 115/350\n",
      "3/3 - 0s - loss: 6952645.0000 - mae: 2027.6920 - val_loss: 11076761.0000 - val_mae: 2639.7317\n",
      "Epoch 116/350\n",
      "3/3 - 0s - loss: 6876061.0000 - mae: 1957.3218 - val_loss: 11001769.0000 - val_mae: 2661.9763\n",
      "Epoch 117/350\n",
      "3/3 - 0s - loss: 6674306.0000 - mae: 1949.9072 - val_loss: 10928261.0000 - val_mae: 2631.8098\n",
      "Epoch 118/350\n",
      "3/3 - 0s - loss: 6714971.5000 - mae: 2004.0010 - val_loss: 10925100.0000 - val_mae: 2627.3030\n",
      "Epoch 119/350\n",
      "3/3 - 0s - loss: 7248569.5000 - mae: 1999.9845 - val_loss: 11368997.0000 - val_mae: 2701.8633\n",
      "Epoch 120/350\n",
      "3/3 - 0s - loss: 6873871.5000 - mae: 1990.6515 - val_loss: 11091795.0000 - val_mae: 2590.9080\n",
      "Epoch 121/350\n",
      "3/3 - 0s - loss: 6728575.5000 - mae: 2034.1342 - val_loss: 10625888.0000 - val_mae: 2520.9595\n",
      "Epoch 122/350\n",
      "3/3 - 0s - loss: 6842009.5000 - mae: 1967.9818 - val_loss: 11916344.0000 - val_mae: 2814.3879\n",
      "Epoch 123/350\n",
      "3/3 - 0s - loss: 7440841.0000 - mae: 2014.4403 - val_loss: 11002043.0000 - val_mae: 2575.5505\n",
      "Epoch 124/350\n",
      "3/3 - 0s - loss: 7288350.0000 - mae: 2060.0701 - val_loss: 11556755.0000 - val_mae: 2613.2297\n",
      "Epoch 125/350\n",
      "3/3 - 0s - loss: 7882898.5000 - mae: 2098.3955 - val_loss: 11361304.0000 - val_mae: 2725.5828\n",
      "Epoch 126/350\n",
      "3/3 - 0s - loss: 6656290.0000 - mae: 1922.2787 - val_loss: 10885749.0000 - val_mae: 2694.2800\n",
      "Epoch 127/350\n",
      "3/3 - 0s - loss: 7212371.5000 - mae: 2129.7896 - val_loss: 11694535.0000 - val_mae: 2677.0310\n",
      "Epoch 128/350\n",
      "3/3 - 0s - loss: 6829860.0000 - mae: 1953.3003 - val_loss: 11764304.0000 - val_mae: 2642.1067\n",
      "Epoch 129/350\n",
      "3/3 - 0s - loss: 6824870.0000 - mae: 1940.8746 - val_loss: 10835441.0000 - val_mae: 2613.8799\n",
      "Epoch 130/350\n",
      "3/3 - 0s - loss: 7030806.5000 - mae: 2066.5349 - val_loss: 10897407.0000 - val_mae: 2630.2202\n",
      "Epoch 131/350\n",
      "3/3 - 0s - loss: 6787175.5000 - mae: 2003.9543 - val_loss: 10970945.0000 - val_mae: 2543.3040\n",
      "Epoch 132/350\n",
      "3/3 - 0s - loss: 6867990.5000 - mae: 1971.8494 - val_loss: 10720924.0000 - val_mae: 2604.7588\n",
      "Epoch 133/350\n",
      "3/3 - 0s - loss: 6688124.0000 - mae: 1920.6517 - val_loss: 10961060.0000 - val_mae: 2703.8142\n",
      "Epoch 134/350\n",
      "3/3 - 0s - loss: 6649069.5000 - mae: 1940.6267 - val_loss: 10807169.0000 - val_mae: 2656.8943\n",
      "Epoch 135/350\n",
      "3/3 - 0s - loss: 6647564.5000 - mae: 1949.1538 - val_loss: 11022356.0000 - val_mae: 2739.2463\n",
      "Epoch 136/350\n",
      "3/3 - 0s - loss: 6605502.5000 - mae: 1947.6888 - val_loss: 10876915.0000 - val_mae: 2697.3450\n",
      "Epoch 137/350\n",
      "3/3 - 0s - loss: 6472169.5000 - mae: 1910.9608 - val_loss: 10959310.0000 - val_mae: 2738.3945\n",
      "Epoch 138/350\n",
      "3/3 - 0s - loss: 6526687.5000 - mae: 1938.1963 - val_loss: 10772543.0000 - val_mae: 2666.6892\n",
      "Epoch 139/350\n",
      "3/3 - 0s - loss: 6472968.5000 - mae: 1894.3767 - val_loss: 10904459.0000 - val_mae: 2720.8005\n",
      "Epoch 140/350\n",
      "3/3 - 0s - loss: 6366908.5000 - mae: 1881.7902 - val_loss: 10899677.0000 - val_mae: 2676.6555\n",
      "Epoch 141/350\n",
      "3/3 - 0s - loss: 6398524.0000 - mae: 1935.8971 - val_loss: 10920259.0000 - val_mae: 2686.6550\n",
      "Epoch 142/350\n",
      "3/3 - 0s - loss: 6424147.5000 - mae: 1895.1287 - val_loss: 11248321.0000 - val_mae: 2799.8884\n",
      "Epoch 143/350\n",
      "3/3 - 0s - loss: 6469367.0000 - mae: 1894.4573 - val_loss: 10979133.0000 - val_mae: 2675.7544\n",
      "Epoch 144/350\n",
      "3/3 - 0s - loss: 6283921.5000 - mae: 1885.0800 - val_loss: 11107175.0000 - val_mae: 2754.0300\n",
      "Epoch 145/350\n",
      "3/3 - 0s - loss: 6302500.5000 - mae: 1853.1149 - val_loss: 11132425.0000 - val_mae: 2765.9973\n",
      "Epoch 146/350\n",
      "3/3 - 0s - loss: 6252803.5000 - mae: 1882.8903 - val_loss: 10973930.0000 - val_mae: 2673.1614\n",
      "Epoch 147/350\n",
      "3/3 - 0s - loss: 6241543.5000 - mae: 1893.7922 - val_loss: 11081425.0000 - val_mae: 2756.1536\n",
      "Epoch 148/350\n",
      "3/3 - 0s - loss: 6228728.5000 - mae: 1864.3367 - val_loss: 11276344.0000 - val_mae: 2820.1895\n",
      "Epoch 149/350\n",
      "3/3 - 0s - loss: 6357222.5000 - mae: 1879.3918 - val_loss: 11014045.0000 - val_mae: 2726.4802\n",
      "Epoch 150/350\n",
      "3/3 - 0s - loss: 6313653.5000 - mae: 1883.5659 - val_loss: 11215461.0000 - val_mae: 2805.2322\n",
      "Epoch 151/350\n",
      "3/3 - 0s - loss: 6160942.5000 - mae: 1861.6104 - val_loss: 11126175.0000 - val_mae: 2665.5718\n",
      "Epoch 152/350\n",
      "3/3 - 0s - loss: 6302647.0000 - mae: 1918.7632 - val_loss: 11031849.0000 - val_mae: 2724.4644\n",
      "Epoch 153/350\n",
      "3/3 - 0s - loss: 6126277.0000 - mae: 1847.7816 - val_loss: 11244323.0000 - val_mae: 2798.6094\n",
      "Epoch 154/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 6250819.5000 - mae: 1847.8002 - val_loss: 11124317.0000 - val_mae: 2762.7429\n",
      "Epoch 155/350\n",
      "3/3 - 0s - loss: 6128114.0000 - mae: 1870.3851 - val_loss: 10987877.0000 - val_mae: 2639.1077\n",
      "Epoch 156/350\n",
      "3/3 - 0s - loss: 6154394.0000 - mae: 1889.7429 - val_loss: 11089042.0000 - val_mae: 2778.7644\n",
      "Epoch 157/350\n",
      "3/3 - 0s - loss: 6182410.5000 - mae: 1853.4342 - val_loss: 10940003.0000 - val_mae: 2739.7214\n",
      "Epoch 158/350\n",
      "3/3 - 0s - loss: 6111356.0000 - mae: 1831.6934 - val_loss: 10961017.0000 - val_mae: 2738.2112\n",
      "Epoch 159/350\n",
      "3/3 - 0s - loss: 6016969.0000 - mae: 1818.0273 - val_loss: 10938092.0000 - val_mae: 2650.0208\n",
      "Epoch 160/350\n",
      "3/3 - 0s - loss: 6119720.0000 - mae: 1872.8743 - val_loss: 11062970.0000 - val_mae: 2764.3105\n",
      "Epoch 161/350\n",
      "3/3 - 0s - loss: 6037227.5000 - mae: 1828.5221 - val_loss: 10969096.0000 - val_mae: 2718.4949\n",
      "Epoch 162/350\n",
      "3/3 - 0s - loss: 6256426.0000 - mae: 1874.4822 - val_loss: 10965808.0000 - val_mae: 2720.5076\n",
      "Epoch 163/350\n",
      "3/3 - 0s - loss: 6006325.5000 - mae: 1812.9873 - val_loss: 11322743.0000 - val_mae: 2856.7937\n",
      "Epoch 164/350\n",
      "3/3 - 0s - loss: 6054138.5000 - mae: 1821.2953 - val_loss: 10964425.0000 - val_mae: 2636.5940\n",
      "Epoch 165/350\n",
      "3/3 - 0s - loss: 6294757.5000 - mae: 1922.6167 - val_loss: 11023735.0000 - val_mae: 2746.2986\n",
      "Epoch 166/350\n",
      "3/3 - 0s - loss: 6089999.5000 - mae: 1847.9084 - val_loss: 11151873.0000 - val_mae: 2774.6477\n",
      "Epoch 167/350\n",
      "3/3 - 0s - loss: 5985148.0000 - mae: 1798.8722 - val_loss: 11235987.0000 - val_mae: 2815.3164\n",
      "Epoch 168/350\n",
      "3/3 - 0s - loss: 6295401.0000 - mae: 1899.3691 - val_loss: 11106933.0000 - val_mae: 2634.1484\n",
      "Epoch 169/350\n",
      "3/3 - 0s - loss: 5967240.5000 - mae: 1852.1228 - val_loss: 11322364.0000 - val_mae: 2841.3196\n",
      "Epoch 170/350\n",
      "3/3 - 0s - loss: 6105126.0000 - mae: 1817.9962 - val_loss: 10932791.0000 - val_mae: 2697.1545\n",
      "Epoch 171/350\n",
      "3/3 - 0s - loss: 5977365.0000 - mae: 1838.1293 - val_loss: 11187856.0000 - val_mae: 2617.2390\n",
      "Epoch 172/350\n",
      "3/3 - 0s - loss: 6235088.0000 - mae: 1914.7968 - val_loss: 11474253.0000 - val_mae: 2875.1914\n",
      "Epoch 173/350\n",
      "3/3 - 0s - loss: 6252351.5000 - mae: 1873.4034 - val_loss: 11045441.0000 - val_mae: 2668.0276\n",
      "Epoch 174/350\n",
      "3/3 - 0s - loss: 6230406.5000 - mae: 1886.4706 - val_loss: 11109866.0000 - val_mae: 2750.0754\n",
      "Epoch 175/350\n",
      "3/3 - 0s - loss: 6211249.0000 - mae: 1815.5798 - val_loss: 11572539.0000 - val_mae: 2894.7402\n",
      "Epoch 176/350\n",
      "3/3 - 0s - loss: 6088613.5000 - mae: 1871.8247 - val_loss: 11436161.0000 - val_mae: 2627.2175\n",
      "Epoch 177/350\n",
      "3/3 - 0s - loss: 6081970.5000 - mae: 1892.2335 - val_loss: 11191467.0000 - val_mae: 2805.6836\n",
      "Epoch 178/350\n",
      "3/3 - 0s - loss: 6184415.5000 - mae: 1814.8101 - val_loss: 11219541.0000 - val_mae: 2799.7434\n",
      "Epoch 179/350\n",
      "3/3 - 0s - loss: 5847842.5000 - mae: 1795.7189 - val_loss: 11306925.0000 - val_mae: 2624.2109\n",
      "Epoch 180/350\n",
      "3/3 - 0s - loss: 6178771.5000 - mae: 1928.5498 - val_loss: 11078555.0000 - val_mae: 2739.6072\n",
      "Epoch 181/350\n",
      "3/3 - 0s - loss: 6257229.5000 - mae: 1829.6196 - val_loss: 11497679.0000 - val_mae: 2887.6614\n",
      "Epoch 182/350\n",
      "3/3 - 0s - loss: 5991352.5000 - mae: 1839.3829 - val_loss: 11368203.0000 - val_mae: 2614.3198\n",
      "Epoch 183/350\n",
      "3/3 - 0s - loss: 6295663.0000 - mae: 1919.1099 - val_loss: 11253485.0000 - val_mae: 2805.1531\n",
      "Epoch 184/350\n",
      "3/3 - 0s - loss: 6330448.0000 - mae: 1861.3217 - val_loss: 11159836.0000 - val_mae: 2759.2949\n",
      "Epoch 185/350\n",
      "3/3 - 0s - loss: 6089406.0000 - mae: 1879.0172 - val_loss: 11411671.0000 - val_mae: 2619.3337\n",
      "Epoch 186/350\n",
      "3/3 - 0s - loss: 5860238.0000 - mae: 1851.4591 - val_loss: 11276779.0000 - val_mae: 2824.1360\n",
      "Epoch 187/350\n",
      "3/3 - 0s - loss: 7018329.5000 - mae: 1963.6194 - val_loss: 11104208.0000 - val_mae: 2777.7063\n",
      "Epoch 188/350\n",
      "3/3 - 0s - loss: 6764933.5000 - mae: 2033.5189 - val_loss: 12225363.0000 - val_mae: 2598.9846\n",
      "Epoch 189/350\n",
      "3/3 - 0s - loss: 6286063.0000 - mae: 1969.8717 - val_loss: 12453615.0000 - val_mae: 3057.8723\n",
      "Epoch 190/350\n",
      "3/3 - 0s - loss: 6458138.5000 - mae: 1886.7648 - val_loss: 11206893.0000 - val_mae: 2631.0632\n",
      "Epoch 191/350\n",
      "3/3 - 0s - loss: 6621074.5000 - mae: 2012.6677 - val_loss: 11405384.0000 - val_mae: 2611.9749\n",
      "Epoch 192/350\n",
      "3/3 - 0s - loss: 5868871.0000 - mae: 1791.7576 - val_loss: 12408325.0000 - val_mae: 3056.9180\n",
      "Epoch 193/350\n",
      "3/3 - 0s - loss: 6296439.0000 - mae: 1853.9730 - val_loss: 10992741.0000 - val_mae: 2613.8923\n",
      "Epoch 194/350\n",
      "3/3 - 0s - loss: 5959945.0000 - mae: 1878.7280 - val_loss: 11269124.0000 - val_mae: 2605.1643\n",
      "Epoch 195/350\n",
      "3/3 - 0s - loss: 5814260.5000 - mae: 1758.2600 - val_loss: 11408217.0000 - val_mae: 2828.7874\n",
      "Epoch 196/350\n",
      "3/3 - 0s - loss: 5985105.5000 - mae: 1806.6934 - val_loss: 11166249.0000 - val_mae: 2656.0532\n",
      "Epoch 197/350\n",
      "3/3 - 0s - loss: 5876233.0000 - mae: 1827.4810 - val_loss: 11217249.0000 - val_mae: 2642.9307\n",
      "Epoch 198/350\n",
      "3/3 - 0s - loss: 5778195.5000 - mae: 1801.9135 - val_loss: 11163719.0000 - val_mae: 2762.9680\n",
      "Epoch 199/350\n",
      "3/3 - 0s - loss: 6034369.5000 - mae: 1822.8297 - val_loss: 11113049.0000 - val_mae: 2682.2090\n",
      "Epoch 200/350\n",
      "3/3 - 0s - loss: 5850204.0000 - mae: 1869.2939 - val_loss: 11684107.0000 - val_mae: 2592.2229\n",
      "Epoch 201/350\n",
      "3/3 - 0s - loss: 5872697.5000 - mae: 1843.3315 - val_loss: 11304403.0000 - val_mae: 2815.7061\n",
      "Epoch 202/350\n",
      "3/3 - 0s - loss: 6188345.5000 - mae: 1848.1761 - val_loss: 11199835.0000 - val_mae: 2655.4968\n",
      "Epoch 203/350\n",
      "3/3 - 0s - loss: 5948056.5000 - mae: 1883.0117 - val_loss: 11615781.0000 - val_mae: 2598.0337\n",
      "Epoch 204/350\n",
      "3/3 - 0s - loss: 6069035.0000 - mae: 1830.4114 - val_loss: 11408256.0000 - val_mae: 2866.8386\n",
      "Epoch 205/350\n",
      "3/3 - 0s - loss: 5783362.0000 - mae: 1773.6760 - val_loss: 11319535.0000 - val_mae: 2634.5442\n",
      "Epoch 206/350\n",
      "3/3 - 0s - loss: 5938850.5000 - mae: 1895.5901 - val_loss: 11364583.0000 - val_mae: 2635.5173\n",
      "Epoch 207/350\n",
      "3/3 - 0s - loss: 5853741.0000 - mae: 1818.7305 - val_loss: 11379828.0000 - val_mae: 2842.1262\n",
      "Epoch 208/350\n",
      "3/3 - 0s - loss: 6027973.5000 - mae: 1815.9907 - val_loss: 11565661.0000 - val_mae: 2613.6282\n",
      "Epoch 209/350\n",
      "3/3 - 0s - loss: 5740616.5000 - mae: 1810.2438 - val_loss: 11182233.0000 - val_mae: 2729.4180\n",
      "Epoch 210/350\n",
      "3/3 - 0s - loss: 5702931.5000 - mae: 1771.6068 - val_loss: 11226627.0000 - val_mae: 2736.0908\n",
      "Epoch 211/350\n",
      "3/3 - 0s - loss: 5980869.0000 - mae: 1846.1846 - val_loss: 11586104.0000 - val_mae: 2626.8738\n",
      "Epoch 212/350\n",
      "3/3 - 0s - loss: 5813604.5000 - mae: 1762.7888 - val_loss: 11307083.0000 - val_mae: 2783.7803\n",
      "Epoch 213/350\n",
      "3/3 - 0s - loss: 5723693.5000 - mae: 1775.2163 - val_loss: 11316927.0000 - val_mae: 2622.3218\n",
      "Epoch 214/350\n",
      "3/3 - 0s - loss: 6166382.5000 - mae: 1938.1992 - val_loss: 11678308.0000 - val_mae: 2647.9504\n",
      "Epoch 215/350\n",
      "3/3 - 0s - loss: 5611804.0000 - mae: 1807.0955 - val_loss: 11778315.0000 - val_mae: 2928.3831\n",
      "Epoch 216/350\n",
      "3/3 - 0s - loss: 6380029.0000 - mae: 1857.2913 - val_loss: 11388989.0000 - val_mae: 2622.6521\n",
      "Epoch 217/350\n",
      "3/3 - 0s - loss: 5872101.0000 - mae: 1875.3853 - val_loss: 11547617.0000 - val_mae: 2623.1887\n",
      "Epoch 218/350\n",
      "3/3 - 0s - loss: 5820992.0000 - mae: 1814.3485 - val_loss: 11430403.0000 - val_mae: 2828.4875\n",
      "Epoch 219/350\n",
      "3/3 - 0s - loss: 6066572.5000 - mae: 1816.3640 - val_loss: 11628267.0000 - val_mae: 2636.1589\n",
      "Epoch 220/350\n",
      "3/3 - 0s - loss: 6053987.0000 - mae: 1907.6255 - val_loss: 11339113.0000 - val_mae: 2662.3713\n",
      "Epoch 221/350\n",
      "3/3 - 0s - loss: 5741704.0000 - mae: 1784.3391 - val_loss: 11420867.0000 - val_mae: 2824.8782\n",
      "Epoch 222/350\n",
      "3/3 - 0s - loss: 5582880.0000 - mae: 1755.6810 - val_loss: 11861705.0000 - val_mae: 2601.9509\n",
      "Epoch 223/350\n",
      "3/3 - 0s - loss: 5950472.5000 - mae: 1895.3602 - val_loss: 11486419.0000 - val_mae: 2641.6931\n",
      "Epoch 224/350\n",
      "3/3 - 0s - loss: 6138419.5000 - mae: 1870.2279 - val_loss: 11319008.0000 - val_mae: 2775.9932\n",
      "Epoch 225/350\n",
      "3/3 - 0s - loss: 5625303.5000 - mae: 1781.3167 - val_loss: 12014691.0000 - val_mae: 2633.1057\n",
      "Epoch 226/350\n",
      "3/3 - 0s - loss: 6437907.5000 - mae: 2012.3624 - val_loss: 11325824.0000 - val_mae: 2634.2451\n",
      "Epoch 227/350\n",
      "3/3 - 0s - loss: 5849616.5000 - mae: 1807.4104 - val_loss: 11642940.0000 - val_mae: 2907.2766\n",
      "Epoch 228/350\n",
      "3/3 - 0s - loss: 5912218.5000 - mae: 1847.3729 - val_loss: 11886364.0000 - val_mae: 2617.4983\n",
      "Epoch 229/350\n",
      "3/3 - 0s - loss: 5934448.5000 - mae: 1865.7672 - val_loss: 11322816.0000 - val_mae: 2686.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/350\n",
      "3/3 - 0s - loss: 5732613.5000 - mae: 1754.5071 - val_loss: 11429923.0000 - val_mae: 2812.2012\n",
      "Epoch 231/350\n",
      "3/3 - 0s - loss: 5751683.5000 - mae: 1776.1312 - val_loss: 11634885.0000 - val_mae: 2628.1331\n",
      "Epoch 232/350\n",
      "3/3 - 0s - loss: 5661810.0000 - mae: 1790.9100 - val_loss: 11327984.0000 - val_mae: 2642.5750\n",
      "Epoch 233/350\n",
      "3/3 - 0s - loss: 5751882.0000 - mae: 1797.0580 - val_loss: 11443364.0000 - val_mae: 2616.5400\n",
      "Epoch 234/350\n",
      "3/3 - 0s - loss: 5881751.0000 - mae: 1866.6689 - val_loss: 11351712.0000 - val_mae: 2630.2991\n",
      "Epoch 235/350\n",
      "3/3 - 0s - loss: 5668965.5000 - mae: 1775.7136 - val_loss: 11293571.0000 - val_mae: 2766.6794\n",
      "Epoch 236/350\n",
      "3/3 - 0s - loss: 5594450.5000 - mae: 1765.2316 - val_loss: 11770421.0000 - val_mae: 2616.6365\n",
      "Epoch 237/350\n",
      "3/3 - 0s - loss: 5630164.5000 - mae: 1795.4426 - val_loss: 11345193.0000 - val_mae: 2733.9412\n",
      "Epoch 238/350\n",
      "3/3 - 0s - loss: 5652067.5000 - mae: 1780.0237 - val_loss: 11458152.0000 - val_mae: 2639.3877\n",
      "Epoch 239/350\n",
      "3/3 - 0s - loss: 5530453.0000 - mae: 1759.2389 - val_loss: 11442411.0000 - val_mae: 2635.4180\n",
      "Epoch 240/350\n",
      "3/3 - 0s - loss: 5506406.5000 - mae: 1760.1343 - val_loss: 11431301.0000 - val_mae: 2626.1545\n",
      "Epoch 241/350\n",
      "3/3 - 0s - loss: 5480935.5000 - mae: 1746.6157 - val_loss: 11365219.0000 - val_mae: 2659.5364\n",
      "Epoch 242/350\n",
      "3/3 - 0s - loss: 5494791.5000 - mae: 1754.4193 - val_loss: 11453205.0000 - val_mae: 2629.8445\n",
      "Epoch 243/350\n",
      "3/3 - 0s - loss: 5481956.0000 - mae: 1754.3446 - val_loss: 11497872.0000 - val_mae: 2625.1853\n",
      "Epoch 244/350\n",
      "3/3 - 0s - loss: 5504740.0000 - mae: 1770.5045 - val_loss: 11440549.0000 - val_mae: 2656.8633\n",
      "Epoch 245/350\n",
      "3/3 - 0s - loss: 5466149.5000 - mae: 1745.0797 - val_loss: 11394448.0000 - val_mae: 2707.6409\n",
      "Epoch 246/350\n",
      "3/3 - 0s - loss: 5684718.5000 - mae: 1754.0089 - val_loss: 11658723.0000 - val_mae: 2633.6675\n",
      "Epoch 247/350\n",
      "3/3 - 0s - loss: 5532826.5000 - mae: 1780.5687 - val_loss: 11754964.0000 - val_mae: 2627.1770\n",
      "Epoch 248/350\n",
      "3/3 - 0s - loss: 5606327.0000 - mae: 1763.2483 - val_loss: 11348096.0000 - val_mae: 2678.3650\n",
      "Epoch 249/350\n",
      "3/3 - 0s - loss: 5587430.5000 - mae: 1766.2322 - val_loss: 11449809.0000 - val_mae: 2631.8604\n",
      "Epoch 250/350\n",
      "3/3 - 0s - loss: 5501968.0000 - mae: 1748.5215 - val_loss: 11336768.0000 - val_mae: 2689.5364\n",
      "Epoch 251/350\n",
      "3/3 - 0s - loss: 5396359.0000 - mae: 1727.4248 - val_loss: 11663316.0000 - val_mae: 2610.9485\n",
      "Epoch 252/350\n",
      "3/3 - 0s - loss: 5712505.0000 - mae: 1833.1150 - val_loss: 11435489.0000 - val_mae: 2625.2419\n",
      "Epoch 253/350\n",
      "3/3 - 0s - loss: 6054043.5000 - mae: 1842.8685 - val_loss: 11387997.0000 - val_mae: 2786.0745\n",
      "Epoch 254/350\n",
      "3/3 - 0s - loss: 6055485.0000 - mae: 1902.1978 - val_loss: 12585389.0000 - val_mae: 2640.5811\n",
      "Epoch 255/350\n",
      "3/3 - 0s - loss: 5522498.0000 - mae: 1780.8307 - val_loss: 11626301.0000 - val_mae: 2850.2532\n",
      "Epoch 256/350\n",
      "3/3 - 0s - loss: 5759573.0000 - mae: 1795.7727 - val_loss: 11474376.0000 - val_mae: 2646.1875\n",
      "Epoch 257/350\n",
      "3/3 - 0s - loss: 6164452.0000 - mae: 1915.6926 - val_loss: 12080869.0000 - val_mae: 2622.0388\n",
      "Epoch 258/350\n",
      "3/3 - 0s - loss: 5895777.0000 - mae: 1807.6276 - val_loss: 11786832.0000 - val_mae: 2902.1963\n",
      "Epoch 259/350\n",
      "3/3 - 0s - loss: 5824752.0000 - mae: 1806.9049 - val_loss: 12476964.0000 - val_mae: 2672.3279\n",
      "Epoch 260/350\n",
      "3/3 - 0s - loss: 5899656.5000 - mae: 1897.2045 - val_loss: 11274232.0000 - val_mae: 2673.3074\n",
      "Epoch 261/350\n",
      "3/3 - 0s - loss: 5682360.5000 - mae: 1789.6182 - val_loss: 11384875.0000 - val_mae: 2824.3918\n",
      "Epoch 262/350\n",
      "3/3 - 0s - loss: 5797524.5000 - mae: 1785.6431 - val_loss: 12736015.0000 - val_mae: 2599.0261\n",
      "Epoch 263/350\n",
      "3/3 - 0s - loss: 5983431.5000 - mae: 1907.8586 - val_loss: 11603827.0000 - val_mae: 2653.8850\n",
      "Epoch 264/350\n",
      "3/3 - 0s - loss: 5623054.0000 - mae: 1780.3132 - val_loss: 11427099.0000 - val_mae: 2656.8108\n",
      "Epoch 265/350\n",
      "3/3 - 0s - loss: 6657872.0000 - mae: 1978.4463 - val_loss: 12341611.0000 - val_mae: 2679.7344\n",
      "Epoch 266/350\n",
      "3/3 - 0s - loss: 6019869.0000 - mae: 1835.6803 - val_loss: 12115965.0000 - val_mae: 3007.8259\n",
      "Epoch 267/350\n",
      "3/3 - 0s - loss: 6549090.5000 - mae: 1929.6665 - val_loss: 12629761.0000 - val_mae: 2595.8474\n",
      "Epoch 268/350\n",
      "3/3 - 0s - loss: 5674845.0000 - mae: 1823.1254 - val_loss: 11952389.0000 - val_mae: 2947.0098\n",
      "Epoch 269/350\n",
      "3/3 - 0s - loss: 5943872.5000 - mae: 1836.0316 - val_loss: 11655957.0000 - val_mae: 2648.4827\n",
      "Epoch 270/350\n",
      "3/3 - 0s - loss: 5869817.5000 - mae: 1885.8303 - val_loss: 12868312.0000 - val_mae: 2672.7136\n",
      "Epoch 271/350\n",
      "3/3 - 0s - loss: 5775293.0000 - mae: 1812.4877 - val_loss: 11814839.0000 - val_mae: 2910.8955\n",
      "Epoch 272/350\n",
      "3/3 - 0s - loss: 5707557.5000 - mae: 1775.6199 - val_loss: 11646901.0000 - val_mae: 2579.4004\n",
      "Epoch 273/350\n",
      "3/3 - 0s - loss: 5639018.0000 - mae: 1844.5763 - val_loss: 11790977.0000 - val_mae: 2606.8108\n",
      "Epoch 274/350\n",
      "3/3 - 0s - loss: 5424696.5000 - mae: 1747.5557 - val_loss: 11658517.0000 - val_mae: 2809.1589\n",
      "Epoch 275/350\n",
      "3/3 - 0s - loss: 5727112.5000 - mae: 1800.3987 - val_loss: 12415571.0000 - val_mae: 2641.2432\n",
      "Epoch 276/350\n",
      "3/3 - 0s - loss: 5608190.0000 - mae: 1838.4198 - val_loss: 11773488.0000 - val_mae: 2638.3843\n",
      "Epoch 277/350\n",
      "3/3 - 0s - loss: 5734534.5000 - mae: 1745.6149 - val_loss: 11662651.0000 - val_mae: 2760.7734\n",
      "Epoch 278/350\n",
      "3/3 - 0s - loss: 6005870.5000 - mae: 1894.6757 - val_loss: 12475464.0000 - val_mae: 2643.6040\n",
      "Epoch 279/350\n",
      "3/3 - 0s - loss: 5653143.0000 - mae: 1820.4945 - val_loss: 11653156.0000 - val_mae: 2828.7766\n",
      "Epoch 280/350\n",
      "3/3 - 0s - loss: 5794981.5000 - mae: 1843.1635 - val_loss: 12309472.0000 - val_mae: 2638.0920\n",
      "Epoch 281/350\n",
      "3/3 - 0s - loss: 5436809.5000 - mae: 1790.0536 - val_loss: 11505189.0000 - val_mae: 2688.5293\n",
      "Epoch 282/350\n",
      "3/3 - 0s - loss: 5500639.5000 - mae: 1755.0818 - val_loss: 11421603.0000 - val_mae: 2674.4680\n",
      "Epoch 283/350\n",
      "3/3 - 0s - loss: 5570154.0000 - mae: 1777.9220 - val_loss: 12085920.0000 - val_mae: 2617.8254\n",
      "Epoch 284/350\n",
      "3/3 - 0s - loss: 5415959.0000 - mae: 1752.2174 - val_loss: 11481643.0000 - val_mae: 2762.3606\n",
      "Epoch 285/350\n",
      "3/3 - 0s - loss: 5483747.0000 - mae: 1756.7061 - val_loss: 11610304.0000 - val_mae: 2622.2092\n",
      "Epoch 286/350\n",
      "3/3 - 0s - loss: 5349282.5000 - mae: 1738.4460 - val_loss: 12059464.0000 - val_mae: 2628.3479\n",
      "Epoch 287/350\n",
      "3/3 - 0s - loss: 5420764.0000 - mae: 1756.3679 - val_loss: 11688777.0000 - val_mae: 2635.5671\n",
      "Epoch 288/350\n",
      "3/3 - 0s - loss: 5486691.5000 - mae: 1737.6078 - val_loss: 11668825.0000 - val_mae: 2659.8428\n",
      "Epoch 289/350\n",
      "3/3 - 0s - loss: 5419919.5000 - mae: 1761.8083 - val_loss: 12476391.0000 - val_mae: 2641.5642\n",
      "Epoch 290/350\n",
      "3/3 - 0s - loss: 5449240.5000 - mae: 1775.3602 - val_loss: 11635632.0000 - val_mae: 2749.0879\n",
      "Epoch 291/350\n",
      "3/3 - 0s - loss: 5551361.0000 - mae: 1768.3269 - val_loss: 11672712.0000 - val_mae: 2659.1182\n",
      "Epoch 292/350\n",
      "3/3 - 0s - loss: 5370234.5000 - mae: 1774.2620 - val_loss: 12444707.0000 - val_mae: 2651.8120\n",
      "Epoch 293/350\n",
      "3/3 - 0s - loss: 5521667.0000 - mae: 1797.0072 - val_loss: 11514229.0000 - val_mae: 2749.0020\n",
      "Epoch 294/350\n",
      "3/3 - 0s - loss: 5450890.0000 - mae: 1767.8438 - val_loss: 11759965.0000 - val_mae: 2619.9753\n",
      "Epoch 295/350\n",
      "3/3 - 0s - loss: 5365835.5000 - mae: 1754.3601 - val_loss: 11821123.0000 - val_mae: 2616.7805\n",
      "Epoch 296/350\n",
      "3/3 - 0s - loss: 5352062.0000 - mae: 1720.4674 - val_loss: 11430008.0000 - val_mae: 2704.5625\n",
      "Epoch 297/350\n",
      "3/3 - 0s - loss: 5772099.5000 - mae: 1829.0283 - val_loss: 11683188.0000 - val_mae: 2623.3630\n",
      "Epoch 298/350\n",
      "3/3 - 0s - loss: 5243827.0000 - mae: 1722.2145 - val_loss: 11525497.0000 - val_mae: 2744.1348\n",
      "Epoch 299/350\n",
      "3/3 - 0s - loss: 5475723.5000 - mae: 1752.1506 - val_loss: 11729421.0000 - val_mae: 2616.9482\n",
      "Epoch 300/350\n",
      "3/3 - 0s - loss: 5438167.5000 - mae: 1766.9418 - val_loss: 12168639.0000 - val_mae: 2622.9556\n",
      "Epoch 301/350\n",
      "3/3 - 0s - loss: 5240586.5000 - mae: 1729.2069 - val_loss: 11540723.0000 - val_mae: 2761.4150\n",
      "Epoch 302/350\n",
      "3/3 - 0s - loss: 5485196.5000 - mae: 1750.4730 - val_loss: 11642547.0000 - val_mae: 2662.5310\n",
      "Epoch 303/350\n",
      "3/3 - 0s - loss: 5333056.0000 - mae: 1748.3966 - val_loss: 12120895.0000 - val_mae: 2634.7112\n",
      "Epoch 304/350\n",
      "3/3 - 0s - loss: 5416987.5000 - mae: 1735.4397 - val_loss: 11537035.0000 - val_mae: 2699.2202\n",
      "Epoch 305/350\n",
      "3/3 - 0s - loss: 5324560.5000 - mae: 1712.5502 - val_loss: 12050624.0000 - val_mae: 2639.9573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/350\n",
      "3/3 - 0s - loss: 5409963.5000 - mae: 1766.4763 - val_loss: 11855836.0000 - val_mae: 2639.3340\n",
      "Epoch 307/350\n",
      "3/3 - 0s - loss: 5366585.0000 - mae: 1742.2268 - val_loss: 11557131.0000 - val_mae: 2797.0674\n",
      "Epoch 308/350\n",
      "3/3 - 0s - loss: 5684012.0000 - mae: 1804.3652 - val_loss: 12235260.0000 - val_mae: 2642.4199\n",
      "Epoch 309/350\n",
      "3/3 - 0s - loss: 5275704.5000 - mae: 1726.1985 - val_loss: 11586085.0000 - val_mae: 2718.2930\n",
      "Epoch 310/350\n",
      "3/3 - 0s - loss: 5400821.0000 - mae: 1736.4637 - val_loss: 12021925.0000 - val_mae: 2614.6082\n",
      "Epoch 311/350\n",
      "3/3 - 0s - loss: 5322925.5000 - mae: 1734.3527 - val_loss: 11813287.0000 - val_mae: 2622.3916\n",
      "Epoch 312/350\n",
      "3/3 - 0s - loss: 5266803.5000 - mae: 1728.5181 - val_loss: 11786432.0000 - val_mae: 2619.6924\n",
      "Epoch 313/350\n",
      "3/3 - 0s - loss: 5305638.0000 - mae: 1748.8956 - val_loss: 11588016.0000 - val_mae: 2676.4309\n",
      "Epoch 314/350\n",
      "3/3 - 0s - loss: 5252032.5000 - mae: 1728.2610 - val_loss: 11866725.0000 - val_mae: 2620.7966\n",
      "Epoch 315/350\n",
      "3/3 - 0s - loss: 5268899.0000 - mae: 1743.0951 - val_loss: 11972084.0000 - val_mae: 2633.8010\n",
      "Epoch 316/350\n",
      "3/3 - 0s - loss: 5312641.0000 - mae: 1746.4172 - val_loss: 11985901.0000 - val_mae: 2630.9866\n",
      "Epoch 317/350\n",
      "3/3 - 0s - loss: 5423770.0000 - mae: 1746.4279 - val_loss: 11727453.0000 - val_mae: 2652.3945\n",
      "Epoch 318/350\n",
      "3/3 - 0s - loss: 5624081.0000 - mae: 1765.6185 - val_loss: 11633316.0000 - val_mae: 2723.3137\n",
      "Epoch 319/350\n",
      "3/3 - 0s - loss: 5203003.0000 - mae: 1767.9797 - val_loss: 13141544.0000 - val_mae: 2668.0154\n",
      "Epoch 320/350\n",
      "3/3 - 0s - loss: 5425386.0000 - mae: 1813.1602 - val_loss: 11597349.0000 - val_mae: 2750.1223\n",
      "Epoch 321/350\n",
      "3/3 - 0s - loss: 5526262.0000 - mae: 1755.3506 - val_loss: 11572829.0000 - val_mae: 2664.1423\n",
      "Epoch 322/350\n",
      "3/3 - 0s - loss: 5232621.0000 - mae: 1737.2339 - val_loss: 12483087.0000 - val_mae: 2608.0320\n",
      "Epoch 323/350\n",
      "3/3 - 0s - loss: 5446604.5000 - mae: 1801.7927 - val_loss: 11552960.0000 - val_mae: 2686.3230\n",
      "Epoch 324/350\n",
      "3/3 - 0s - loss: 5597922.0000 - mae: 1753.3125 - val_loss: 11529347.0000 - val_mae: 2700.7571\n",
      "Epoch 325/350\n",
      "3/3 - 0s - loss: 5304143.0000 - mae: 1748.4296 - val_loss: 12855565.0000 - val_mae: 2614.5837\n",
      "Epoch 326/350\n",
      "3/3 - 0s - loss: 5594535.0000 - mae: 1835.3511 - val_loss: 11590931.0000 - val_mae: 2772.9258\n",
      "Epoch 327/350\n",
      "3/3 - 0s - loss: 5456966.5000 - mae: 1748.0426 - val_loss: 11838204.0000 - val_mae: 2623.9402\n",
      "Epoch 328/350\n",
      "3/3 - 0s - loss: 5326061.0000 - mae: 1763.6499 - val_loss: 12603843.0000 - val_mae: 2642.4043\n",
      "Epoch 329/350\n",
      "3/3 - 0s - loss: 5199485.0000 - mae: 1748.6700 - val_loss: 11643544.0000 - val_mae: 2770.5830\n",
      "Epoch 330/350\n",
      "3/3 - 0s - loss: 5905140.5000 - mae: 1801.1082 - val_loss: 11660957.0000 - val_mae: 2676.6580\n",
      "Epoch 331/350\n",
      "3/3 - 0s - loss: 5069590.5000 - mae: 1698.1449 - val_loss: 13021232.0000 - val_mae: 2629.7983\n",
      "Epoch 332/350\n",
      "3/3 - 0s - loss: 5570822.0000 - mae: 1837.2277 - val_loss: 11505665.0000 - val_mae: 2715.6113\n",
      "Epoch 333/350\n",
      "3/3 - 0s - loss: 5360444.5000 - mae: 1760.7472 - val_loss: 11556597.0000 - val_mae: 2684.1213\n",
      "Epoch 334/350\n",
      "3/3 - 0s - loss: 5255970.0000 - mae: 1788.5026 - val_loss: 12596861.0000 - val_mae: 2638.8972\n",
      "Epoch 335/350\n",
      "3/3 - 0s - loss: 5396455.0000 - mae: 1745.6515 - val_loss: 11656471.0000 - val_mae: 2674.8359\n",
      "Epoch 336/350\n",
      "3/3 - 0s - loss: 5201657.5000 - mae: 1707.0791 - val_loss: 11950955.0000 - val_mae: 2624.9895\n",
      "Epoch 337/350\n",
      "3/3 - 0s - loss: 5188986.5000 - mae: 1722.3905 - val_loss: 11607341.0000 - val_mae: 2653.3506\n",
      "Epoch 338/350\n",
      "3/3 - 0s - loss: 5210661.5000 - mae: 1718.6561 - val_loss: 11757380.0000 - val_mae: 2612.7136\n",
      "Epoch 339/350\n",
      "3/3 - 0s - loss: 5131950.5000 - mae: 1730.0618 - val_loss: 12258499.0000 - val_mae: 2609.0576\n",
      "Epoch 340/350\n",
      "3/3 - 0s - loss: 5633453.5000 - mae: 1797.6376 - val_loss: 11485192.0000 - val_mae: 2709.2893\n",
      "Epoch 341/350\n",
      "3/3 - 0s - loss: 5102317.5000 - mae: 1706.9244 - val_loss: 12584111.0000 - val_mae: 2624.7483\n",
      "Epoch 342/350\n",
      "3/3 - 0s - loss: 5275535.0000 - mae: 1759.6051 - val_loss: 11863000.0000 - val_mae: 2620.6531\n",
      "Epoch 343/350\n",
      "3/3 - 0s - loss: 5249342.0000 - mae: 1747.3861 - val_loss: 11794733.0000 - val_mae: 2686.9412\n",
      "Epoch 344/350\n",
      "3/3 - 0s - loss: 5089592.5000 - mae: 1697.0841 - val_loss: 12690965.0000 - val_mae: 2621.2473\n",
      "Epoch 345/350\n",
      "3/3 - 0s - loss: 5674858.5000 - mae: 1843.8639 - val_loss: 11856328.0000 - val_mae: 2631.6833\n",
      "Epoch 346/350\n",
      "3/3 - 0s - loss: 5941257.0000 - mae: 1811.6323 - val_loss: 11512893.0000 - val_mae: 2762.4626\n",
      "Epoch 347/350\n",
      "3/3 - 0s - loss: 5596341.5000 - mae: 1799.7754 - val_loss: 13648884.0000 - val_mae: 2651.9070\n",
      "Epoch 348/350\n",
      "3/3 - 0s - loss: 5568146.5000 - mae: 1777.6844 - val_loss: 11606623.0000 - val_mae: 2812.9851\n",
      "Epoch 349/350\n",
      "3/3 - 0s - loss: 5416358.0000 - mae: 1749.9617 - val_loss: 12299947.0000 - val_mae: 2629.6130\n",
      "Epoch 350/350\n",
      "3/3 - 0s - loss: 5277252.0000 - mae: 1720.6250 - val_loss: 11956205.0000 - val_mae: 2632.0488\n",
      "MSE: 11956205.000, RMSE: 3457.775, MAE: 2632.049\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=350, batch_size=32, verbose=2, validation_data=(X_test, y_test))\n",
    "# evaluate the model\n",
    "mse, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (mse, sqrt(mse), mae))\n",
    "# make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3affc8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 15372.854\n"
     ]
    }
   ],
   "source": [
    "row = asarray([18024.0, 16722.0, 14385.0, 21342.0, 17180.0]).reshape((1, n_steps, 1))\n",
    "yhat = model.predict(row)\n",
    "print('Predicted: %.3f' % (yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
